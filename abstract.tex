
\begin{abstract}
The Rubin Observatory's Data Butler is designed to allow data file location and file formats to be of no concern to the people writing the science pipeline algorithms. The Butler works in conjunction with the workflow graph builder to allow pipelines to be constructed from the algorithmic tasks. These pipelines can be executed at scale using object stores and multi-node clusters, or on a laptop using a local file system. The Butler and pipeline system are now in daily use during Rubin construction and early operations.
As the Commissioning Execution Plan (LSE-390) says, "The project team shall
deliver all reports documenting the as-built hardware and software including:
drawings, source code, modifications, compliance exceptions, and recommendations
for improvement." As a first step towards the delivery of documents that will describe the system at the
end of construction, we are assembling teams for producing of the order 40 papers
that eventually will be submitted to relevant professional journals. The immediate goal is to accomplish
all the writing that can be done without data analysis before the data
taking begins, and the team becomes much more busy and stressed.

This document provides the template for these papers.
\end{abstract}

